input {
  file {
    path => "/app/logs/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => plain
  }
}

filter {
  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:json_part}" }
  }

  if "_grokparsefailure" in [tags] {
    drop { }
  }

  json {
    source => "json_part"
    target => "parsed"
  }

  if "_jsonparsefailure" in [tags] {
    drop { }
  }

  mutate {
    rename => { "[parsed][timestamp]" => "timestamp" }
    rename => { "[parsed][service]" => "service" }
    rename => { "[parsed][endpoint]" => "endpoint" }
    rename => { "[parsed][http_method]" => "http_method" }
    rename => { "[parsed][http_status]" => "http_status" }
    rename => { "[parsed][response_time_ms]" => "response_time_ms" }
    rename => { "[parsed][error_flag]" => "error_flag" }
    rename => { "[parsed][environment]" => "environment" }
    rename => { "[parsed][request_id]" => "request_id" }
    rename => { "[parsed][trace_id]" => "trace_id" }
    rename => { "[parsed][span_id]" => "span_id" }
    rename => { "[parsed][payload_size_bytes]" => "payload_size_bytes" }
    rename => { "[parsed][cpu_usage_percent]" => "cpu_usage_percent" }
    rename => { "[parsed][memory_usage_mb]" => "memory_usage_mb" }
    rename => { "[parsed][log_level]" => "log_level" }
    rename => { "[parsed][error_message]" => "error_message" }
    remove_field => ["parsed", "json_part", "host", "log", "@version", "event.original"]
  }

  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "logstash-microservices-%{+YYYY.MM.dd}"
  }

  stdout { codec => rubydebug }
}
